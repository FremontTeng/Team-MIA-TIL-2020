{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing of all the necessary mods\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "# from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv files\n",
    "#fashion_df = pd.read_csv(\"./datasets/fashion_text_dataset.csv\")\n",
    "# Reading csv file of train set\n",
    "fashion_df = pd.read_csv(\"./datasets/TIL_NLP_train_dataset.csv\")\n",
    "# Reading csv file of test set\n",
    "fashion_test_df = pd.read_csv(\"./datasets/TIL_NLP_test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word_representation</th>\n",
       "      <th>outwear</th>\n",
       "      <th>top</th>\n",
       "      <th>trousers</th>\n",
       "      <th>women dresses</th>\n",
       "      <th>women skirts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>w7718 w173355 w138132 w232277 w90685 w314686 w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>w195317 w127737 w171593 w22890 w342007 w217871...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>w247655 w270233 w261113 w337250 w366000 w37873...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>w279289 w395855 w61795 w286461 w308610 w27013 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>w254516 w135431 w115724 w331534 w256214 w71240...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>w53495 w306061 w372126 w47982 w66980 w189406 w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>w237465 w256553 w286461 w382662 w206066 w12125...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>w173317 w39222 w207614 w136665 w394246 w197783...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>w373517 w37419 w358253 w162965 w286461 w204762...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>w230409 w109269 w369689 w186076 w377961 w21787...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>w210717 w371473 w227401 w66980 w369717 w133157...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>w304300 w236555 w365489 w15393 w256905 w292000...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>w318673 w361433 w90685 w236919 w3366 w1867 w12...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>w365885 w123298 w366000 w217871 w147343 w34893...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>w80884 w385278 w34893 w121255 w42500 w186076 w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>w371004 w500024 w27013 w30571 w144920 w337551 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>w342153 w133512 w310983 w1867 w120979 w70597 w...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>w155034 w256553 w374089 w368487 w276473 w34921...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>w366000 w500157 w7718 w500013 w282225 w188064 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>w41024 w237465 w256553 w95569 w174897 w103096 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                word_representation  outwear  top  \\\n",
       "0    0  w7718 w173355 w138132 w232277 w90685 w314686 w...        1    0   \n",
       "1    1  w195317 w127737 w171593 w22890 w342007 w217871...        1    0   \n",
       "2    2  w247655 w270233 w261113 w337250 w366000 w37873...        0    1   \n",
       "3    3  w279289 w395855 w61795 w286461 w308610 w27013 ...        1    0   \n",
       "4    4  w254516 w135431 w115724 w331534 w256214 w71240...        1    0   \n",
       "5    5  w53495 w306061 w372126 w47982 w66980 w189406 w...        1    0   \n",
       "6    6  w237465 w256553 w286461 w382662 w206066 w12125...        1    0   \n",
       "7    7  w173317 w39222 w207614 w136665 w394246 w197783...        1    1   \n",
       "8    8  w373517 w37419 w358253 w162965 w286461 w204762...        1    0   \n",
       "9    9  w230409 w109269 w369689 w186076 w377961 w21787...        1    1   \n",
       "10  10  w210717 w371473 w227401 w66980 w369717 w133157...        0    1   \n",
       "11  11  w304300 w236555 w365489 w15393 w256905 w292000...        1    0   \n",
       "12  12  w318673 w361433 w90685 w236919 w3366 w1867 w12...        0    1   \n",
       "13  13  w365885 w123298 w366000 w217871 w147343 w34893...        1    0   \n",
       "14  14  w80884 w385278 w34893 w121255 w42500 w186076 w...        1    0   \n",
       "15  15  w371004 w500024 w27013 w30571 w144920 w337551 ...        1    0   \n",
       "16  16  w342153 w133512 w310983 w1867 w120979 w70597 w...        0    1   \n",
       "17  17  w155034 w256553 w374089 w368487 w276473 w34921...        0    0   \n",
       "18  18  w366000 w500157 w7718 w500013 w282225 w188064 ...        1    1   \n",
       "19  19  w41024 w237465 w256553 w95569 w174897 w103096 ...        1    1   \n",
       "\n",
       "    trousers  women dresses  women skirts  \n",
       "0          1              0             0  \n",
       "1          1              0             0  \n",
       "2          1              0             0  \n",
       "3          1              0             0  \n",
       "4          1              0             0  \n",
       "5          0              0             1  \n",
       "6          0              1             0  \n",
       "7          1              0             0  \n",
       "8          0              0             0  \n",
       "9          0              0             0  \n",
       "10         0              0             0  \n",
       "11         1              0             0  \n",
       "12         1              0             0  \n",
       "13         0              0             0  \n",
       "14         1              0             0  \n",
       "15         1              0             0  \n",
       "16         0              0             0  \n",
       "17         1              0             0  \n",
       "18         0              0             0  \n",
       "19         0              0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the first few columns of the train dataset\n",
    "fashion_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word_representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>w373517 w383437 w374393 w87179 w289496 w327385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>w237465 w167111 w279437 w194870 w351537 w17560...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>w151648 w93366 w121255 w193800 w71240 w48576 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>w182664 w317736 w33852 w111248 w45374 w209361 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>w206647 w236725 w99560 w338476 w75409 w36882 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>w256553 w182887 w239430 w96414 w276473 w217871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>w305957 w254429 w215751 w155034 w287643 w45765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>w318673 w350483 w356690 w186076 w151648 w34893...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>w500001 w128292 w253354 w254516 w102910 w37439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>w41024 w237465 w95569 w174897 w103096 w237465 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                word_representation\n",
       "0   0  w373517 w383437 w374393 w87179 w289496 w327385...\n",
       "1   1  w237465 w167111 w279437 w194870 w351537 w17560...\n",
       "2   2  w151648 w93366 w121255 w193800 w71240 w48576 w...\n",
       "3   3  w182664 w317736 w33852 w111248 w45374 w209361 ...\n",
       "4   4  w206647 w236725 w99560 w338476 w75409 w36882 w...\n",
       "5   5  w256553 w182887 w239430 w96414 w276473 w217871...\n",
       "6   6  w305957 w254429 w215751 w155034 w287643 w45765...\n",
       "7   7  w318673 w350483 w356690 w186076 w151648 w34893...\n",
       "8   8  w500001 w128292 w253354 w254516 w102910 w37439...\n",
       "9   9  w41024 w237465 w95569 w174897 w103096 w237465 ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the first few columns of the test dataset\n",
    "fashion_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of Train Set\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7380 entries, 0 to 7379\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   7380 non-null   int64 \n",
      " 1   word_representation  7380 non-null   object\n",
      " 2   outwear              7380 non-null   int64 \n",
      " 3   top                  7380 non-null   int64 \n",
      " 4   trousers             7380 non-null   int64 \n",
      " 5   women dresses        7380 non-null   int64 \n",
      " 6   women skirts         7380 non-null   int64 \n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 403.7+ KB\n",
      "\n",
      "Information of Test Set\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2460 entries, 0 to 2459\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   2460 non-null   int64 \n",
      " 1   word_representation  2460 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 38.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#This displays the relevant information of the dataframe\n",
    "#Train Set\n",
    "print(\"Information of Train Set\\n\")\n",
    "fashion_df.info()\n",
    "#Test Set\n",
    "print(\"\\nInformation of Test Set\\n\")\n",
    "fashion_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Matrix Conversion\n",
    "For word embedding (using CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary back from the pickle file.\n",
    "import pickle\n",
    "\n",
    "words = pickle.load( open( \"./datasets/word_embeddings.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out random mask:  [-0.2974     0.13021    0.44774   -0.51027   -0.15967    0.34781\n",
      " -0.0073979  0.19348   -0.37376   -0.16468    0.64726   -0.33593\n",
      " -0.34176    0.033171  -0.32817   -0.50221   -0.19317   -0.53613\n",
      " -0.87927   -0.39061    0.69842    0.2139    -0.68798    0.73236\n",
      "  0.94687   -0.42926    0.3609    -0.43389    0.30961    0.48626\n",
      "  0.43969    0.58117   -0.46265   -0.28028   -0.02724    0.25968\n",
      " -0.73342    0.11206   -0.31721    0.045954  -0.67666   -0.30504\n",
      " -0.53005   -0.030116  -0.10036   -0.18755    0.26206   -1.2814\n",
      "  0.31223   -0.4429     0.37722   -0.18759    0.96948    1.2398\n",
      " -0.068121  -2.361     -0.086176   0.38622    1.6444     0.51647\n",
      " -0.55111    0.91737   -0.66038   -0.28121    0.37626   -0.35154\n",
      "  0.66515   -0.17435    0.61422    0.21745   -0.67409    0.36388\n",
      "  0.058988   0.052989   0.3081    -0.32066   -0.18457   -0.51273\n",
      " -1.0552    -0.25697    0.36672   -0.02435   -0.37087   -0.0038253\n",
      " -0.96345   -0.19426   -0.099656  -0.62601   -0.33331   -0.0708\n",
      "  0.027776   0.16697    0.20021   -0.039847  -1.1718     0.49732\n",
      " -0.39451   -0.024439   0.25522    0.27765  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing out random mask: \",words[\"w365885\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(words.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing Mods\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding## Plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)# Others\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word embeddings\n",
    "embeddings_index = dict()\n",
    "for line in words:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(words)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Weighted Matrix (Incomplete)\n",
    "#embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "#for word, index in tokenizer.word_index.items():\n",
    "#    if index > vocabulary_size - 1:\n",
    "#        break\n",
    "#    else:\n",
    "#        embedding_vector = embeddings_index.get(word)\n",
    "#        if embedding_vector is not None:\n",
    "#            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary modules \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec \n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "keys = np.array(list(words.keys()))\n",
    "model = Word2Vec(keys, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=11, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "#Print out model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "# summarize vocabulary\n",
    "words = list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.42384470e-01 -5.42612970e-02  3.04510802e-01 -1.71501905e-01\n",
      " -2.46663973e-01 -5.31137645e-01 -5.63695014e-01 -3.91395442e-04\n",
      "  2.37625446e-02 -5.72090782e-02  3.98752570e-01  1.39456525e-01\n",
      " -2.04495043e-01  2.80202925e-01  2.22028598e-01  5.52487224e-02\n",
      "  9.76192132e-02  1.10968255e-01 -1.47381052e-01  9.80239511e-02\n",
      "  1.81352481e-01  9.74731371e-02 -2.94957608e-01 -5.54291159e-02\n",
      " -3.61579269e-01 -1.70854464e-01 -2.61028912e-02  4.46648985e-01\n",
      "  8.34959969e-02  4.78527725e-01 -4.20618922e-01 -1.58530623e-01\n",
      " -3.23513716e-01 -4.10511196e-01 -2.59529263e-01  3.52950454e-01\n",
      "  1.44535094e-01 -1.47943854e-01 -1.64518982e-01  3.11634660e-01\n",
      "  6.04795516e-01  7.26058856e-02  1.87233046e-01 -1.87156841e-01\n",
      "  6.49046246e-03 -8.17626193e-02 -5.49643189e-02 -2.44306967e-01\n",
      " -2.06213847e-01 -3.46590042e-01 -2.88790196e-01  6.99248239e-02\n",
      " -5.18031955e-01 -5.42897463e-01  4.42513615e-01 -4.50396270e-01\n",
      " -1.33172870e-01  1.65596068e-01 -4.09031034e-01  2.30557412e-01\n",
      "  5.79254292e-02 -5.95918536e-01  9.60538685e-02 -1.25721335e-01\n",
      " -1.59868468e-02 -3.09482396e-01 -2.03121662e-01  1.55448973e-01\n",
      " -2.90062856e-02  3.63575697e-01 -4.55938846e-01 -3.17073822e-01\n",
      "  1.05810978e-01  1.97820030e-02 -4.14016008e-01 -1.41086340e-01\n",
      "  2.31357664e-01  1.99193597e-01 -2.97848642e-01  2.61961579e-01\n",
      "  2.48314768e-01 -4.63905513e-01 -2.16391981e-02 -1.44106239e-01\n",
      " -3.88402075e-01 -4.07466531e-01 -6.93899393e-02 -3.44586253e-01\n",
      " -2.82022595e-01 -1.80130780e-01  6.32672489e-01  2.41325453e-01\n",
      " -1.36929855e-01 -2.17860743e-01  3.02329063e-01 -2.37372950e-01\n",
      " -6.44018769e-01  4.80167925e-01 -8.67867291e-01  1.20924905e-01]\n"
     ]
    }
   ],
   "source": [
    "# access vector for one word\n",
    "print(model['w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a 2d PCA model to the vectors\n",
    "X = model[model.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(model.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- End of word embedding --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This displays the value count of the various categories\n",
    "#Total outwear counts\n",
    "fashion_df.outwear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total top counts\n",
    "fashion_df.top.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total trousers counts\n",
    "fashion_df.trousers.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total women dresses counts\n",
    "fashion_df[fashion_df.columns[5]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total women skirts counts\n",
    "fashion_df[fashion_df.columns[6]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This displays the number of unique word representation in the dataframe\n",
    "NO_OF_CLASSES = len(fashion_df.word_representation.unique())\n",
    "NO_OF_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check any text that are not processed yet\n",
    "def print_text(index):\n",
    "    example = fashion_df[fashion_df.index == index][fashion_df.columns.values].values[0]\n",
    "    if len(example) > 0:\n",
    "        print('ID: ', example[0])\n",
    "        print('Word Representation: ', example[1])\n",
    "        description = \"\"\n",
    "        if (example[2]):\n",
    "            description += 'Outwear '\n",
    "        if (example[3]):\n",
    "            description += 'Top '\n",
    "        if (example[4]):\n",
    "            description += 'Trousers '\n",
    "        if (example[5]):\n",
    "            description += 'Women Dresses '\n",
    "        if (example[6]):\n",
    "            description += 'Women Skirts '\n",
    "        print('Description: ', description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of the text that is printed out using the index\n",
    "print_text(13)\n",
    "print_text(2121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants set to replace these symbols from the text\n",
    "REPLACE_BY_SPACE = re.compile('[/(){}\\[\\]\\|@,;-]')\n",
    "BAD_SYMBOLS = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function use to clean up the text\n",
    "def clean_text(text):\n",
    "\n",
    "    # Make all the text to lowercases\n",
    "    text = text.lower() \n",
    "    \n",
    "    # replace REPLACE_BY_SPACE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE with space.\n",
    "    text = REPLACE_BY_SPACE.sub(' ', text) \n",
    "    \n",
    "    # remove symbols which are in BAD_SYMBOLS from text. substitute the matched string in BAD_SYMBOLS with nothing. \n",
    "    text = BAD_SYMBOLS.sub('', text) \n",
    "    \n",
    "    # remove stopwords from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the new description after cleaning the text\n",
    "#fashion_df['description'] = fashion_df['description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out the example texts again for double checking.\n",
    "print_text(13)\n",
    "print_text(2121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Samples\n",
    "train_samples = fashion_df[\"word_representation\"].values\n",
    "#Train Labels\n",
    "train_labels = fashion_df[[\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"]].values\n",
    "print(\"Words: \", train_samples[0])\n",
    "print(\"Showing id 0 :\", train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the test and train sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_samples, train_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out the test and train set shapes\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_FEATURES = 20000\n",
    "# Max number of words in each description\n",
    "MAX_LENGTH = 50\n",
    "# This is fixed\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the number of unique tokens\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens.'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the shape of the data tensor\n",
    "X = tokenizer.texts_to_sequences(fashion_df['word_representation'].values)\n",
    "X = pad_sequences(X, maxlen = MAX_LENGTH)\n",
    "print('Shape of data tensor:{}'.format(X.shape))\n",
    "#X  #DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of label tensor:{}'.format(Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, val_test, data_label, val_label = train_test_split(X, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and display the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_FEATURES, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(NO_OF_CLASSES, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables for epochs and batch size\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "models = model.fit(X_train, Y_train, \n",
    "                   epochs=EPOCHS, batch_size=BATCH_SIZE,validation_split=0.1,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                            patience=3, \n",
    "                                            min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Loss Graph of the model\n",
    "plt.title('Loss')\n",
    "plt.plot(models.history['loss'], label='train')\n",
    "plt.plot(models.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the accuracy graph of the model\n",
    "plt.title('Accuracy')\n",
    "plt.plot(models.history['accuracy'], label='train')\n",
    "plt.plot(models.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the accuracy of the test set and print out both loss and accuracy of test set\n",
    "accuracy = model.evaluate(X_test,Y_test)\n",
    "#print('Test set\\nLoss: {}\\nAccuracy: {}'.format(accuracy[0],accuracy[1]))\n",
    "print('Test set\\nLoss: {:0.5f}\\nAccuracy: {:0.5f}'.format(accuracy[0],accuracy[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess test data\n",
    "\n",
    "yhat = model.predict(X_test, verbose=0)\n",
    "preds_labels = [[1 if x > 0.5 else 0 for idx,x in enumerate(i) ] for i in yhat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multilabel_confusion_matrix(Y_test, preds_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the ROC-AUC Score\n",
    "#print(average_precision_score(y_test, preds_labels))\n",
    "#print(f1_score(y_test, preds_labels, average='micro'))\n",
    "print('ROC-AUC Score:', roc_auc_score(Y_test, preds_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- Just for fun -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with new text description\n",
    "\n",
    "TEXT = [\"He is wearing a dark blue t-shirt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_description = TEXT\n",
    "seq = tokenizer.texts_to_sequences(new_description)\n",
    "padded = pad_sequences(seq, maxlen=MAX_LENGTH)\n",
    "pred = model.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = fashion_df.category.unique().tolist()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)\n",
    "print(labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- END -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
